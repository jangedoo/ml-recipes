{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- To classify gender of a person in an image using convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data file which contains urls of images and their corresponding labels (male or female). We'll check the data distribution and then proceed to download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>please_select_the_gender_of_the_person_in_the_picture</th>\n",
       "      <th>please_select_the_gender_of_the_person_in_the_picture:confidence</th>\n",
       "      <th>image_url</th>\n",
       "      <th>please_select_the_gender_of_the_person_in_the_picture_gold</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023132475</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/19/2016 17:00:25</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/users/40...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1023132476</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/19/2016 17:00:48</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/users/42...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023132477</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/19/2016 17:01:43</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/users/44...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023132478</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/19/2016 17:01:04</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/users/47...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023132479</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/19/2016 17:00:48</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/users/50...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id _golden _unit_state  _trusted_judgments   _last_judgment_at  \\\n",
       "0  1023132475   False   finalized                   1  8/19/2016 17:00:25   \n",
       "1  1023132476   False   finalized                   1  8/19/2016 17:00:48   \n",
       "2  1023132477   False   finalized                   1  8/19/2016 17:01:43   \n",
       "3  1023132478   False   finalized                   1  8/19/2016 17:01:04   \n",
       "4  1023132479   False   finalized                   1  8/19/2016 17:00:48   \n",
       "\n",
       "  please_select_the_gender_of_the_person_in_the_picture  \\\n",
       "0                                               male      \n",
       "1                                               male      \n",
       "2                                               male      \n",
       "3                                               male      \n",
       "4                                               male      \n",
       "\n",
       "   please_select_the_gender_of_the_person_in_the_picture:confidence  \\\n",
       "0                                                1.0                  \n",
       "1                                                1.0                  \n",
       "2                                                1.0                  \n",
       "3                                                1.0                  \n",
       "4                                                1.0                  \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://d1qb2nb5cznatu.cloudfront.net/users/40...   \n",
       "1  https://d1qb2nb5cznatu.cloudfront.net/users/42...   \n",
       "2  https://d1qb2nb5cznatu.cloudfront.net/users/44...   \n",
       "3  https://d1qb2nb5cznatu.cloudfront.net/users/47...   \n",
       "4  https://d1qb2nb5cznatu.cloudfront.net/users/50...   \n",
       "\n",
       "  please_select_the_gender_of_the_person_in_the_picture_gold  user_id  \n",
       "0                                                NaN               40  \n",
       "1                                                NaN               42  \n",
       "2                                                NaN               44  \n",
       "3                                                NaN               47  \n",
       "4                                                NaN               50  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data_source.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records =  64084\n"
     ]
    }
   ],
   "source": [
    "print(\"Total records = \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many columns that we don't care about and the column names are very long as well. We'll only select a subset of columns as well as rename them. Then we'll also select only the rows that has confidence of 1. pandas makes it very easy to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records =  64075\n"
     ]
    }
   ],
   "source": [
    "# select only the columns that we are interested in\n",
    "df = df[[\"_unit_id\", \"please_select_the_gender_of_the_person_in_the_picture\", \n",
    "    \"please_select_the_gender_of_the_person_in_the_picture:confidence\", \"image_url\"]]\n",
    "\n",
    "# rename the columns\n",
    "df.columns = [\"id\", \"gender\", \"confidence\", \"url\"]\n",
    "\n",
    "# only select the rows that has confidence of 1.0\n",
    "df = df[df[\"confidence\"] == 1]\n",
    "\n",
    "print(\"Total records = \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many samples we have for each gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>7364</td>\n",
       "      <td>7364</td>\n",
       "      <td>7364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>47592</td>\n",
       "      <td>47592</td>\n",
       "      <td>47592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsure</th>\n",
       "      <td>9119</td>\n",
       "      <td>9119</td>\n",
       "      <td>9119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  confidence    url\n",
       "gender                          \n",
       "female   7364        7364   7364\n",
       "male    47592       47592  47592\n",
       "unsure   9119        9119   9119"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"gender\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of images for \"male\". There are also some images with gender \"unsure\". We'll visualize few data samples from each category and then sample the data in such a way that each category has more or less same number of samples. This is important to make sure that the model learns equally about all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to display image urls\n",
    "from IPython.display import HTML, display\n",
    "def display_images(df, category_name=\"male\", count=12):\n",
    "    filtered_df = df[df[\"gender\"] == category_name]\n",
    "    p = np.random.permutation(len(filtered_df))\n",
    "    p = p[:count]\n",
    "    img_style = \"width:180px; margin:0px; float:left;border:1px solid black;\"\n",
    "    images_list = \"\".join([\"<img style='{}' src='{}'/>\".format(img_style, u) for u in filtered_df.iloc[p].url])\n",
    "    display(HTML(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1398853-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/842062-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/165920-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/406208-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/448812-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1281951-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/947045-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/332128-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/45282-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/127256-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1223348-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/316082-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/754331-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/881190-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/156641-large'/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(df, category_name=\"male\", count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/138715-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/62074-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1097767-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/852769-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/158856-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/615246-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/271131-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/85487-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/98641-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1167251-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/11757-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/445714-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/605325-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/875721-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1381787-large'/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(df, category_name=\"female\", count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/245906-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/185077-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1437361-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1104613-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/73800-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/508679-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1377541-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/384088-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/162253-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/46773-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/7194-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1075366-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/472268-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/513486-large'/><img style='width:180px; margin:0px; float:left;border:1px solid black;' src='https://d1qb2nb5cznatu.cloudfront.net/users/1036122-large'/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_images(df, category_name=\"unsure\", count=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in \"unsure\" category are either not images of a person or it contains more than one person or the person's face is not facing the camera. There are also some images which could perfectly be labelled as a male or a female. Similarly in \"male\" and \"female\" category we can see some images of a cartoon or just text. For now we'll just ignore those for simplicity. If our model does not perform well, then we'll revisit the data cleaning part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total male samples =  7364\n",
      "Total female samples =  7364\n"
     ]
    }
   ],
   "source": [
    "df_male = df[df[\"gender\"] == \"male\"]\n",
    "df_female = df[df[\"gender\"] == \"female\"]\n",
    "\n",
    "# to make both categories have equal number of samples\n",
    "# we'll take the counts of the category that has lowest\n",
    "# number\n",
    "min_samples = min(len(df_male), len(df_female))\n",
    "\n",
    "# for indexing randomly\n",
    "p = np.random.permutation(min_samples)\n",
    "\n",
    "df_male = df_male.iloc[p]\n",
    "df_female = df_female.iloc[p]\n",
    "\n",
    "print(\"Total male samples = \", len(df_male))\n",
    "print(\"Total female samples = \", len(df_female))\n",
    "\n",
    "df = pd.concat([df_male, df_female])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def download_images(df, data_dir=\"./data\"):\n",
    "    genders = df[\"gender\"].unique()\n",
    "    for g in genders:\n",
    "        g_dir = \"{}/{}\".format(data_dir, g)\n",
    "        if not os.path.exists(g_dir):\n",
    "            os.makedirs(g_dir)\n",
    "            \n",
    "    for index, row in tqdm.tqdm_notebook(df.iterrows()):\n",
    "        filepath = \"{}/{}/{}.jpg\".format(data_dir, row[\"gender\"], row[\"id\"])\n",
    "        if os.path.exists(filepath):\n",
    "            continue\n",
    "        try:\n",
    "            resp = requests.get(row[\"url\"])\n",
    "            im = Image.open(BytesIO(resp.content))\n",
    "            im.save(filepath)\n",
    "        except:\n",
    "            print(\"Error while downloading %s\" % row[\"url\"])\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "download_images(df, data_dir=DATA_DIR)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split the data into training and testing set. There are some images that were not properly downloaded and are corrupted which we will remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + \"/train\"\n",
    "TEST_DIR = DATA_DIR + \"/test\"\n",
    "\n",
    "for d in [TRAIN_DIR, TEST_DIR]:\n",
    "    for g in df[\"gender\"].unique():\n",
    "        final_dir = \"{}/{}\".format(d, g)\n",
    "        if not os.path.exists(final_dir):\n",
    "            os.makedirs(final_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "split_ratio = 0.7 # we'll reserve 70% of the images for training set\n",
    "\n",
    "def validate_and_move(files, target_dir):\n",
    "    for f in tqdm.tqdm_notebook(files):\n",
    "        # try to open the file to make sure that this is not corrupted\n",
    "        try:\n",
    "            im = Image.open(f)\n",
    "            shutil.copy(f, target_dir)\n",
    "        except:\n",
    "            pass\n",
    "#             os.remove(f)\n",
    "\n",
    "for gender in df[\"gender\"].unique():\n",
    "    gender_dir = \"{}/{}\".format(DATA_DIR, gender)\n",
    "    pattern = \"{}/*.jpg\".format(gender_dir)\n",
    "    all_files = glob.glob(pattern)\n",
    "    shuffle(all_files)\n",
    "    \n",
    "    train_up_to = math.ceil(len(all_files) * split_ratio)\n",
    "    train_files = all_files[:train_up_to]\n",
    "    test_files = all_files[train_up_to:]\n",
    "    \n",
    "    \n",
    "    validate_and_move(train_files, TRAIN_DIR + \"/\" + gender)\n",
    "    validate_and_move(test_files, TEST_DIR + \"/\" + gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we did some basic visualization and prepared our dataset. We'll build and train a model in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
